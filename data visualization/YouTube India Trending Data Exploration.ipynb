{"cells":[{"metadata":{"_uuid":"1e7c18e3ae5770d737d9da52221d854a791e051e","_cell_guid":"f9a2b71f-3452-4357-aefe-ccd5abf5cf6d"},"cell_type":"markdown","source":"# YouTube India Data Exploration\n### Data Exploration and Visualization With Python\n***\n\n"},{"metadata":{"_uuid":"46752ee0b531542e2ee00e0984026ce08547404f","_cell_guid":"5bd5450d-2e32-4c46-aed1-184cd1fd927e"},"cell_type":"markdown","source":"<img src='https://upload.wikimedia.org/wikipedia/commons/e/e1/Logo_of_YouTube_%282015-2017%29.svg'>"},{"metadata":{"_uuid":"3c625c678819bc4c3167bf60488d68e729f5fda0","_cell_guid":"075d4522-3274-40c2-828b-36b673e8935c"},"cell_type":"markdown","source":"# Table of Contents\n\n* [1. Importing dataset and data preprocessing](#importing_dataset_and_data_preprocessing) <br>\n * [1.1. Importing essential libraries](#importing_essential_libraries) <br>\n * [1.2. Importing datasets](#importing_datasets) <br>\n * [1.3. Let's summarize the datasets](#lets_summarize_the_dataset) <br>\n * [1.4. Data preprocessing and feature engineering](#data_preprocessing_and_feature_engineering) <br>\n   * [1.4.1. Removing Column 'Description'](#description-removing) <br>\n   * [1.4.2. Datetime format of Trending date and Publish time](#datetime_format_of_trending_date_and_publish_time) <br>\n   * [1.4.3. Assignment of the film category](#assignment_of_the_film_category) <br>\n   * [1.4.4. Dislike percentage](#dislike_percentage) <br>\n   * [1.4.5. Number of words with all upper case in title](#number_of_words_with_all_upper_case_in_title) <br>\n   * [1.4.6. Distribution of basic parameters](#distribution_of_basic_parameters) <br>\n   * [1.4.7. What about duplicates?](#what_about_duplicates) <br>\n   * [1.4.8. Days before trend](#time_to_trend) <br>\n   * [1.4.9. Missing Value for Category Columns](#missing_value) <br>\n   * [1.4.10. Addition of column 'Views per day'](#views_per_day) <br>\n   * [1.4.11. Outputing the file in CSV Format](#output_file) <br>\n<br>\n* [2. Data Visualization](#data_visualization) <br>\n * [2.1. Best time to publish video](#best_time_to_publish_video) <br>\n * [2.2. Correlation between dataset variables](#correlation) <br>\n * [2.3. It got viral](#it_got_viral) <br>\n * [2.4. Most influential creators](#most_influential_creators) <br>\n * [2.5. Variety of topics](#variety_of_topics) <br>\n * [2.6. Average time interval](#avg_time_interval) <br>\n * [2.7. Late bloomers](#late_bloomers) <br>\n * [2.8. No such thing as bad press, right?](#no_such_thing_as_bad_press_right) <br>\n * [2.9. Tags wordcloud](#tags_wordcloud) <br>\n * [2.10. Likes vs dislikes distribution!](#likes_vs_dislikes_distribution) <br>\n\n* [3. References](#refer) <br>"},{"metadata":{"_uuid":"21ad4084136bfa8419f01051971f7da0d47b28ed","_cell_guid":"a6cf4878-7d6c-4d60-9ab6-daa6102d48ac"},"cell_type":"markdown","source":"## 1. Importing dataset and data preprocessing\n<a id=\"importing_dataset_and_data_preprocessing\"></a>"},{"metadata":{"_uuid":"2e39c72435537be1fa82fc85560a2bd74e6ea6de","_cell_guid":"a291dd18-d247-4a5a-a5cd-fb1bfea20bf3"},"cell_type":"markdown","source":"### 1.1. Importing essential libraries\n<a id=\"importing_essential_libraries\"></a> "},{"metadata":{"_uuid":"2181057768174d863673707a4ff7d32edb66ab2d","_cell_guid":"6d109b9a-c8e5-445f-a0e0-943dc852a6d8","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy.optimize import curve_fit\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fb6ed97f916dfb4c50551cc8c3590ac048014ce","_cell_guid":"ddfdc496-84a5-495f-ac18-257ccf5d9950"},"cell_type":"markdown","source":"### 1.2. Importing dataset\n<a id=\"importing_datasets\"></a>"},{"metadata":{"_uuid":"56d7a3e9384798eea3fddae84a113a876916dc9f","_cell_guid":"418db61a-b689-4178-b98d-ca1059b8c53f","trusted":true,"collapsed":true},"cell_type":"code","source":"in_videos = pd.read_csv('../input/INvideos.csv')\nin_videos_categories = pd.read_json('../input/IN_category_id.json')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6984a78c2c21d77e16aa19c53936d54e4c564b1c","_cell_guid":"8a91b294-1208-49e1-9cfa-6176c7cd9501"},"cell_type":"markdown","source":"### 1.3. Let's summarize the dataset\n<a id=\"lets_summarize_the_dataset\"></a>"},{"metadata":{"_uuid":"9888e5c91a5c1e2b29c48929bdfe826f4ae6b21b","_cell_guid":"500af2ad-1eae-44f0-9eb7-3604db6f3234","trusted":true},"cell_type":"code","source":"in_videos.head(1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45e18f639f3a43278a9e4176818d7afc3b3a621d","_cell_guid":"4bd4dfbc-21fd-4d94-93cb-1e0409ad134c","trusted":true},"cell_type":"code","source":"in_videos.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dde7465a4deca0336adc24c4451b66a5e00203e6","_cell_guid":"a2c5ada5-edcc-4b6e-922b-3e5406bfa6ad"},"cell_type":"markdown","source":"### 1.4. Data preprocessing and feature engineering\n<a id=\"data_preprocessing_and_feature_engineering\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### 1.4.1. Removing Column 'Description'\n<a id=\"description-removing\"></a>\nSummary and Titles are creating some issues with shifting the whole row into some next cell in the final csv output file. We are ignoring rows of data of that nature."},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"in_videos = in_videos.drop(['description'], axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4b5b1ff8eb9c80592f3f931b2ae33c98dac3fb3","_cell_guid":"239471c6-5228-46e9-ae46-e1bef98ed131"},"cell_type":"markdown","source":"### 1.4.2. Datetime format of Trending date and Publish time\n<a id=\"datetime_format_of_trending_date_and_publish_time\"></a>"},{"metadata":{"_uuid":"45b435f6d19e3bc790cdb2b0527bbba54310d45f","_cell_guid":"2e3b6a33-d494-435b-982d-ba4b067f245e"},"cell_type":"markdown","source":"<b>NOTE:</b> Firstly we will transform ```trending_date``` as well as ```publish_time``` from string to datetime format. This will allow us to easily perform arithmetic operations and compare these values. ```publish_time``` column will be divided into three separate ones ```publish_date```, ```publish_time``` and  ```publish_hour``` ."},{"metadata":{"_uuid":"e2d3578bb245a67e2842d334844124dc528a0d43","_cell_guid":"6dd2adfc-aed2-49f2-bb88-624166e3f598","trusted":true,"collapsed":true},"cell_type":"code","source":"################################### Use only once (Fails after 1st Attempt) ##################################\n# Transforming Trending date column to datetime format\nin_videos['trending_date'] = pd.to_datetime(in_videos['trending_date'], format='%y.%d.%m').dt.date\n\n# Transforming Trending date column to datetime format and splitting into two separate ones\npublish_time = pd.to_datetime(in_videos['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\nin_videos['publish_date'] = publish_time.dt.date\nin_videos['publish_time'] = publish_time.dt.time\nin_videos['publish_hour'] = publish_time.dt.hour","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fb70165490ed0f42f96c39a30c9c29902083371","scrolled":true,"_cell_guid":"c83ecaee-e2a1-420a-acb4-2d268401be78","trusted":true},"cell_type":"code","source":"in_videos.head(1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b916f9c46dddef54b882056421aceacb9807871","_cell_guid":"2a295bcc-1836-4024-adea-f4b6623952fb"},"cell_type":"markdown","source":"### 1.4.3. Addition of column 'category'\n<a id=\"assignment_of_the_film_category\"></a>"},{"metadata":{"_uuid":"62052eaadedd5fd806afe7e3521454051d004976","_cell_guid":"bec3379c-2e5d-4988-8537-1b420d952f3b"},"cell_type":"markdown","source":"<b>NOTE:</b> Next we will connect the ```category``` with the ```category_id``` they belong to. We will associate the information in two files: ```INvideos.csv``` and ```IN_category_id.json``` ."},{"metadata":{"_uuid":"ae8f29516ae62eb0936ab03d27edc28a7e9e7647","_cell_guid":"2d5d5c88-2890-4524-9549-1ca80e913285","trusted":true},"cell_type":"code","source":"################################### Use only once (Fails after 1st Attempt) ##################################\n# We'll use a very nice python featur - dictionary comprehension, to extract most important data from IN_category_id.json\ncategories = {category['id']: category['snippet']['title'] for category in in_videos_categories['items']}\n\n# Now we will create new column that will represent name of category\nin_videos.insert(4, 'category', in_videos['category_id'].astype(str).map(categories))\nin_videos.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"186c47ee4edf4ccbcc159014d83014def5095359","_cell_guid":"32c00924-13ca-45ec-bff0-3aedf9edaee1"},"cell_type":"markdown","source":"### 1.4.4. Dislike percentage (For Visualization Section)\n<a id=\"dislike_percentage\"></a>"},{"metadata":{"_uuid":"d735dc4b39b14064622d5f40d33718eadbe7c21d","_cell_guid":"7c70c125-8b6f-4265-a2e4-e9f1d1779be3"},"cell_type":"markdown","source":"<b>NOTE:</b> We also count what percentage of assessments are negative ratings."},{"metadata":{"_uuid":"bbdee604702402add0885528ef431876e0ed8beb","_cell_guid":"a0f511df-21ae-4f0b-baa2-f08949aad382","trusted":true},"cell_type":"code","source":"in_videos_first = in_videos.copy() \nin_videos_first['dislike_percentage'] = in_videos['dislikes'] / (in_videos['dislikes'] + in_videos['likes'])\nprint(in_videos_first['dislike_percentage'].head(5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d89ce1d9c3359163a666943638b21e4f58555ca","_cell_guid":"48991080-daf4-43f0-90ee-407f92cd1eda"},"cell_type":"markdown","source":"### 1.4.5. Number of words with all upper case in title (For Visualization Section)\n<a id=\"number_of_words_with_all_upper_case_in_title\"></a>"},{"metadata":{"_uuid":"7b5df17a3ac8c7cb1af2ab19c2f934fd412d355a","_cell_guid":"8675f7c2-ed4e-4af3-b350-425f74563ec6","trusted":true},"cell_type":"code","source":"# Helper function\ndef numberOfUpper(string):\n    i = 0\n    for word in string.split():\n        if word.isupper():\n            i += 1\n    return(i)\n\nin_videos_first[\"all_upper_in_title\"] = in_videos[\"title\"].apply(numberOfUpper)\nprint(in_videos_first[\"all_upper_in_title\"].tail(5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12b6fe7ac18c797948ca6647f34fb8c5637514fe","_cell_guid":"4f167da2-37f8-4e87-b3eb-259c71ba3050"},"cell_type":"markdown","source":"### 1.4.6. Distribution of basic parameters (For Visualization Section)\n<a id=\"distribution_of_basic_parameters\"></a>"},{"metadata":{"_uuid":"bca356a9853bf1b7e193c4011ec37056d4e8c93f","_cell_guid":"c85faf3c-d0f6-43d8-a18b-6b9e00effae0","trusted":true},"cell_type":"code","source":"in_videos_first['likes_log'] = np.log(in_videos['likes'] + 1)\nin_videos_first['views_log'] = np.log(in_videos['views'] + 1)\nin_videos_first['dislikes_log'] = np.log(in_videos['dislikes'] + 1)\nin_videos_first['comment_log'] = np.log(in_videos['comment_count'] + 1)\n\nplt.figure(figsize = (12,6))\n\nplt.subplot(221)\ng1 = sns.distplot(in_videos_first['views_log'])\ng1.set_title(\"VIEWS LOG DISTRIBUITION\", fontsize=16)\n\nplt.subplot(224)\ng2 = sns.distplot(in_videos_first['likes_log'],color='green')\ng2.set_title('LIKES LOG DISTRIBUITION', fontsize=16)\n\nplt.subplot(223)\ng3 = sns.distplot(in_videos_first['dislikes_log'], color='r')\ng3.set_title(\"DISLIKES LOG DISTRIBUITION\", fontsize=16)\n\nplt.subplot(222)\ng4 = sns.distplot(in_videos_first['comment_log'])\ng4.set_title(\"COMMENTS LOG DISTRIBUITION\", fontsize=16)\n\nplt.subplots_adjust(wspace = 0.2, hspace = 0.4,top = 0.9)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd7ac445abb7ea1251ffdb33d50c83f4c038a511","_cell_guid":"68694a5a-d689-4ca5-a69c-377b4d1bdd18"},"cell_type":"markdown","source":"### 1.4.7. What about duplicates? (For Visualization Section)\n<a id=\"what_about_duplicates\"></a>"},{"metadata":{"_uuid":"5828ac28f5bad9ec2741225f3ddb55aa4addc1a3","_cell_guid":"149506aa-d139-4ac8-a108-16ed1cd95c61"},"cell_type":"markdown","source":"<b>NOTE:</b> Because many of the films have been trending you several times, we will create a separate datasets in which we will get rid of repetitions. Still, we leave the original dataset, because there is a lot of interesting information in it."},{"metadata":{"_uuid":"947dadd8ef7a3a9e1d1a16a196d8b11700aa5510","_cell_guid":"f0ea26df-9670-46b2-8dca-90aa577b921c","trusted":true},"cell_type":"code","source":"in_videos_last = in_videos.drop_duplicates(subset=['video_id'], keep='last', inplace=False)\nin_videos_first = in_videos.drop_duplicates(subset=['video_id'], keep='first', inplace=False)\nprint(in_videos_last.head(2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8ca812b161f6016ddf105ddfbcc76076f4be2ae","scrolled":false,"_cell_guid":"954a745a-6409-40bf-9170-13737c6fec7e","trusted":true},"cell_type":"code","source":"print(\"in_videos dataset contains {} videos\".format(in_videos.shape[0]))\nprint(\"in_videos_first dataset contains {} videos\".format(in_videos_first.shape[0]))\nprint(\"in_videos_last dataset contains {} videos\".format(in_videos_last.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aff774c371a25898c23d453bff47cfb74d8ab4a8","_cell_guid":"5bb67e92-463f-49df-abb9-61d50b5d6adc"},"cell_type":"markdown","source":"### 1.4.8. Addition of column 'Days before trend'\n<a id=\"time_to_trend\"></a>"},{"metadata":{"_uuid":"cbea685edab8137dca2db0aa0ccd849dfc4aed93","_cell_guid":"754c7802-104a-4052-9737-0cf0af10a3f3"},"cell_type":"markdown","source":"<b>NOTE:</b> Lastly we will create new feature ```days_before_trend``` representing the time (in days) between publication and the day when it became trending."},{"metadata":{"_uuid":"1221a0448f69dc0e34f3c245fae5737c8952c004","_cell_guid":"1dbd784c-d4ec-4f60-8ed1-598cbe461ad2","scrolled":true,"trusted":true},"cell_type":"code","source":"in_videos[\"days_before_trend\"] = (in_videos.trending_date - in_videos.publish_date) / np.timedelta64(1, 'D')\nin_videos[\"days_before_trend\"] = in_videos[\"days_before_trend\"].astype(int)\nin_videos.tail(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.4.9. Missing Value for Category Columns\n<a id=\"missing_value\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"in_videos.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_data = in_videos[in_videos[\"category\"].isnull()]\nnull_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"in_videos[\"category\"].fillna(\"Nonprofits & Activism\", inplace = True) \nin_videos[in_videos[\"category_id\"]  == 29]\nin_videos[in_videos[\"category_id\"]  == 29].tail(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.4.10. Addition of column 'Views per day'\n<a id=\"views_per_day\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"in_videos.loc[(in_videos['days_before_trend'] < 1), 'days_before_trend'] = 1\nin_videos[\"views_per_day\"] = in_videos[\"views\"].astype(int) / in_videos[\"days_before_trend\"]\nin_videos[\"views_per_day\"] = in_videos[\"views_per_day\"]\nin_videos.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"in_videos.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.4.11. Outputing the file in CSV Format \n<a id=\"output_file\"></a>"},{"metadata":{},"cell_type":"markdown","source":"<b>NOTE:</b> Producing output as processed file after preprocessing step in the pipeline as .csv file. The next step will take preprocessed csv file as input for model to train. "},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"in_videos.to_csv('preprocessedIndia.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6b8e3f7fd62a1d738d19caa552427f1fdf33a65","_cell_guid":"4c77ebbe-5765-43f9-82f5-e732aa661ed4"},"cell_type":"markdown","source":"## 2. Data Visualization\n<a id=\"data_visualization\"></a>"},{"metadata":{"_uuid":"208eed3e1d127dc0fdbd79e78470eb80d060f931","_cell_guid":"862a92ce-31bd-410f-9c23-804c3d2dbbf7"},"cell_type":"markdown","source":"### 2.1. Best time to publish video\n<a id=\"best_time_to_publish_video\"></a>"},{"metadata":{"_uuid":"8cf1cdef28eb23c9ef94428b886eba1e970d8fed","_cell_guid":"3bf399cf-52f9-4705-ac7b-ebfe803c5ed6","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# Initialization of the list storing counters for subsequent publication hours\npublish_h = [0] * 24\n\nfor index, row in in_videos_first.iterrows():\n    publish_h[row[\"publish_hour\"]] += 1\n    \nvalues = publish_h\nind = np.arange(len(values))\n\n\n# Creating new plot\nfig = plt.figure(figsize=(20,10))\nax = fig.add_subplot(111)\nax.yaxis.grid()\nax.xaxis.grid()\nbars = ax.bar(ind, values)\n\n# Sampling of Colormap\nfor i, b in enumerate(bars):\n    b.set_color(plt.cm.viridis((values[i] - min(values))/(max(values)- min(values))))\n    \nplt.ylabel('Number of videos that got trending', fontsize=20)\nplt.xlabel('Time of publishing', fontsize=20)\nplt.title('Best time to publish video', fontsize=35, fontweight='bold')\nplt.xticks(np.arange(0, len(ind), len(ind)/6), [0, 4, 8, 12, 16, 20])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2. Correlation between dataset variables\n<a id=\"correlation\"></a>\nNow let's see how the dataset variables are correlated with each other: for example, we would like to see how views and likes are correlated, meaning do views and likes increase and decrease together (positive correlation)? Does one of them increase when the other decrease and vice versa (negative correlation)? Or are they not correlated?\n\nCorrelation is represented as a value between -1 and +1 where +1 denotes the highest positive correlation, -1 denotes the highest negative correlation, and 0 denotes that there is no correlation.\n\nLet's visualize the correlation table between our dataset variables using a heatmap."},{"metadata":{"trusted":true},"cell_type":"code","source":"h_labels = [x.replace('_', ' ').title() for x in \n            list(in_videos.select_dtypes(include=['number', 'bool']).columns.values)]\n\nfig, ax = plt.subplots(figsize=(10,6))\n_ = sns.heatmap(in_videos.corr(), annot=True, xticklabels=h_labels, yticklabels=h_labels, cmap=sns.cubehelix_palette(as_cmap=True), ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d74c7d922cf161d1bd3cac34efc2963c2d7df8b","_cell_guid":"adfcb4ea-e41d-4215-a6e6-5ac159da3ee6"},"cell_type":"markdown","source":"### 2.3. It got sensational viral\n<a id=\"it_got_viral\"></a>\nIt take few minutes to get the thumbnail from the internet (at live) for top 10 trending video from the dataset."},{"metadata":{"_uuid":"84285fd09a1dc6fbd78220e03a620d6e36dfd596","_cell_guid":"243dfd02-bbfc-4467-adb3-6195a4a476b3","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from IPython.display import HTML, display\n\n# We choose the 10 most trending videos\nselected_columns = ['title', 'channel_title', 'thumbnail_link', 'publish_date', 'category']\n\nmost_frequent = in_videos.groupby(selected_columns)['video_id'].agg(\n    {\"code_count\": len}).sort_values(\n    \"code_count\", ascending=False\n).head(10).reset_index()\n\n# Construction of HTML table with miniature photos assigned to the most popular movies\ntable_content = ''\nmax_title_length = 50\n\nfor date, row in most_frequent.T.iteritems():\n    HTML_row = '<tr>'\n    HTML_row += '<td><img src=\"' + str(row[2]) + '\"style=\"width:100px;height:100px;\"></td>'\n    HTML_row += '<td>' + str(row[1]) + '</td>'\n    HTML_row += '<td>' + str(row[0])  + '</td>'\n    HTML_row += '<td>' + str(row[4]) + '</td>'\n    HTML_row += '<td>' + str(row[3]) + '</td>'\n    \n    table_content += HTML_row + '</tr>'\n\ndisplay(HTML(\n    '<table><tr><th>Photo</th><th>Channel Name</th><th style=\"width:250px;\">Title</th><th>Category</th><th>Publish Date</th></tr>{}</table>'.format(table_content))\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a355ec13481e17f0a9a6e418cbdcc4e6c3f70afe","_cell_guid":"81b5b96d-539d-4ee1-ab4a-a8a618c43109"},"cell_type":"markdown","source":"### 2.4. Most influential creators (By Channel)\n<a id=\"most_influential_creators\"></a>"},{"metadata":{"_uuid":"e8fa6cdf2c3390cbdaec3ec8cd00978231bdd971","scrolled":false,"_cell_guid":"13d2f6b4-e32a-4c30-a839-08b86f377bf7","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"max_title_length = 20\nnumber_of_creators = 20\n\ntop_creators = in_videos.groupby(['channel_title'])['channel_title'].agg(\n    {\"code_count\": len}).sort_values(\n    \"code_count\", ascending=False\n).head(number_of_creators).reset_index()\n\ntrace1 = go.Bar(\n    y = [(x if len(x) <= max_title_length else x[:max_title_length] + \"...\") for x in top_creators.channel_title.values][::-1],\n    x = top_creators['code_count'].tolist()[::-1],\n    name = \"Top creators\",\n    orientation = 'h',\n    marker=dict(\n        color='rgba(55, 128, 191, 0.7)',\n        line=dict(\n            color='rgba(55, 128, 191, 1.0)',\n            width=2,\n        )\n    ),\n)\n\ndata = [trace1]\n\nlayout = go.Layout(\n    title = 'Most influential creators',\n    width=900,\n    height=600,\n    margin=go.Margin(\n        l=180,\n        r=50,\n        b=80,\n        t=80,\n        pad=10\n    ),\n    paper_bgcolor='rgb(244, 238, 225)',\n    plot_bgcolor='rgb(244, 238, 225)',\n    yaxis = dict(\n        anchor = 'x',\n        rangemode='tozero',\n        tickfont=dict(\n            size=10\n        ),\n        ticklen=1\n    ), \n    xaxis = dict(\n        title= 'Number of times video made by creator got trending',\n        anchor = 'x',\n        rangemode='tozero'\n    ), \n    legend=dict(x=0.6, y=0.07)\n)\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df5753a9f04cc72c44a11a232ca20b9dc200625b","_cell_guid":"12e14dcd-ced2-4d41-80a8-c276fa902470"},"cell_type":"markdown","source":"### 2.5. Variety of topics\n<a id=\"variety_of_topics\"></a>"},{"metadata":{"_uuid":"9a5ad5737044317cf96d482ef3aae2971dd37221","_cell_guid":"c4e05960-0ef4-4e6c-b876-13832abb63a3","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"max_title_length = 30\nnumber_of_creators = 12\n\ntop_creators = in_videos.groupby(['category'])['category'].agg(\n    {\"code_count\": len}).sort_values(\n    \"code_count\", ascending=False\n).head(number_of_creators).reset_index()\n\ntrace1 = go.Bar(\n    y = [(x if len(x) <= max_title_length else x[:max_title_length] + \"...\") for x in top_creators.category.values][::-1],\n    x = top_creators['code_count'].tolist()[::-1],\n    name = \"Top categories\",\n    orientation = 'h',\n    marker=dict(\n        color='rgba(55, 128, 191, 0.7)',\n        line=dict(\n            color='rgba(55, 128, 191, 1.0)',\n            width=2,\n        )\n    ),\n)\n\ndata = [trace1]\n\nlayout = go.Layout(\n    title = 'Most popular categories',\n    width=900,\n    height=600,\n    margin=go.Margin(\n        l=180,\n        r=50,\n        b=80,\n        t=80,\n        pad=10\n    ),\n    paper_bgcolor='rgb(244, 238, 225)',\n    plot_bgcolor='rgb(244, 238, 225)',\n    yaxis = dict(\n        anchor = 'x',\n        rangemode='tozero',\n        tickfont=dict(\n            size=10\n        ),\n        ticklen=1\n    ), \n    xaxis = dict(\n        title= 'The number of times the video of a given category was trending',\n        anchor = 'x',\n        rangemode='tozero'\n    ), \n    legend=dict(x=0.6, y=0.07)\n)\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.6. Average time interval\n<a id=\"avg_time_interval\"></a>\nThe average time interval for each category describes on average how fast a video can show up on the trending board. This is also a important criterion that which need to be cared about, because the longer time interval is, the larger the time cost will be."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Average time interval between published and trending\nin_videos['interval'] = (pd.to_datetime(in_videos['trending_date']).dt.date - pd.to_datetime(in_videos['publish_date']).dt.date).astype('timedelta64[D]')\ndf_t = pd.DataFrame(in_videos['interval'].groupby(in_videos['category']).mean())\nplt.figure(figsize = (32,12))\nplt.plot(df_t, color='skyblue', linewidth=2)\nplt.title(\"Average Days to be trending video\", fontsize=25)\nplt.xlabel('Category',fontsize=22)\nplt.ylabel('Average Time Interval',fontsize=22)\nplt.tick_params(labelsize=14)\nplt.show();\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2acbb4d63e33f12a3502c6519480463b2dd8f9c1","_cell_guid":"0521f2f4-7cc2-4fc6-8ccd-923dc21528a1"},"cell_type":"markdown","source":"### 2.7. Late bloomers\n<a id=\"late_bloomers\"></a>\nThis section dedicated to videos that waited the longest before they became trending. I also checked how many views they had when they hit the YouTube home page."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(in_videos[\"video_id\"]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6e6e898bc4f53a12183947e0ef518b44dfe868e","scrolled":false,"_cell_guid":"15c892cc-740b-4b70-9d7d-04d0ed0d0059","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# dropping passed values \n\n#in_videos.drop(in_videos.video_id == '\"zUZ1z7FwLc8\",\"CLl1RbxDRAs\",\"z3V9LUA6VQM\", \"jElRtesCnlA\", \"qP67alYxSiU\", \"JSkOecmAFFo\", \"l3fRny54z4U\", \"UTVFNrRwL1o\", \"K6JyjjNnTlg\", \"4tEqzEo5uKY\", \"8vBjlhp73hU\", \"KskjXRkmJW4\", \"NTiSvK7c810\", \"sOwXjFMy17Y\", \"h6Z9mmSNJcw\"'), inplace = True) \nmax_title_length = 20\nnumber_of_late_bloomers = 15\nin_videos_first[\"days_before_trend\"]= in_videos[\"days_before_trend\"].astype(float)\nlate_bloomers = in_videos_first.sort_values([\"days_before_trend\"], ascending=False).head(number_of_late_bloomers)\nlate_bloomers_title = [(x if len(x) <= max_title_length else x[:max_title_length] + \"...\") for x in late_bloomers.title.values]\nlate_bloomers_days = late_bloomers.days_before_trend.values\nlate_bloomers_views = late_bloomers.views.values\n\ntrace1 = go.Bar(\n    x = late_bloomers_title,\n    y = late_bloomers_days,\n    name='Number of days',\n    marker=dict(\n        color='rgba(55, 128, 191, 0.7)',\n        line=dict(\n            color='rgba(55, 128, 191, 1.0)',\n            width=2,\n        )\n    )\n)\ntrace2 = go.Bar(\n    x = late_bloomers_title,\n    y = late_bloomers_views,\n    name='total views',\n    marker=dict(\n        color='rgba(219, 64, 82, 0.7)',\n        line=dict(\n            color='rgba(219, 64, 82, 1.0)',\n            width=2,\n        )\n    ),\n    yaxis='y2'\n)\n\n\ndata = [trace1, trace2]\nlayout = go.Layout(\n    barmode='group',\n    title = 'Late bloomers',\n    width=900,\n    height=500,\n    margin=go.Margin(\n        l=75,\n        r=75,\n        b=120,\n        t=80,\n        pad=10\n    ),\n    paper_bgcolor='rgb(244, 238, 225)',\n    plot_bgcolor='rgb(244, 238, 225)',\n    yaxis = dict(\n        title= 'Number of days until becoming trending',\n        anchor = 'x',\n        rangemode='tozero'\n    ),   \n    yaxis2=dict(\n        title='Total number of views',\n        titlefont=dict(\n            color='rgb(148, 103, 189)'\n        ),\n        tickfont=dict(\n            color='rgb(148, 103, 189)'\n        ),\n        overlaying='y',\n        side='right',\n        anchor = 'x',\n        rangemode = 'tozero',\n        dtick = 61000\n    ),\n    #legend=dict(x=-.1, y=1.2)\n    legend=dict(x=0.1, y=0.05)\n)\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2b6c6be943ed01109fad12063751834799bf6a2","_cell_guid":"d91fd115-ab51-4d5d-b320-0a3039d52ee2"},"cell_type":"markdown","source":"### 2.8. No such thing as bad press, right?\n<a id=\"no_such_thing_as_bad_press_right\"></a>\nThis section dedicated to videos that has gained popularity on YT by being disliked."},{"metadata":{"_uuid":"dc153cb0d137e4590707de2cf14da54c5b73bc1f","_cell_guid":"78c478f0-6db3-47b1-b502-9056bdcbf9e4","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"max_title_length = 20\nnumber_of_late_bloomers = 10\nin_videos_first[\"dislikes\"]= in_videos[\"dislikes\"]\nin_videos_first['dislike_percentage'] = in_videos['dislikes'] / (in_videos['dislikes'] + in_videos['likes'])\nmost_disliked = in_videos_first.sort_values([\"dislikes\"], ascending=False).head(number_of_late_bloomers)\nmost_disliked_title = [(x if len(x) <= max_title_length else x[:max_title_length] + \"...\") for x in late_bloomers.title.values]\nmost_disliked_l_number = most_disliked.likes.values\nmost_disliked_dl_number = most_disliked.dislikes.values\nmost_disliked_dl_percentage = most_disliked.dislike_percentage.values\n\ntrace1 = go.Bar(\n    x = most_disliked_title,\n    y = most_disliked_l_number,\n    name='Number of likes',\n    marker=dict(\n        color='rgba(55, 128, 191, 0.7)',\n        line=dict(\n            color='rgba(55, 128, 191, 1.0)',\n            width=2,\n        )\n    )\n)\ntrace2 = go.Bar(\n    x = most_disliked_title,\n    y = most_disliked_dl_number,\n    name='Number of dislikes',\n    marker=dict(\n        color='rgba(219, 64, 82, 0.7)',\n        line=dict(\n            color='rgba(219, 64, 82, 1.0)',\n            width=2,\n        )\n    )\n)\n\ntrace3 = go.Scatter(\n    x = most_disliked_title,\n    y = most_disliked_dl_percentage,\n    name='Dislike percentage',\n    mode = 'markers',\n    marker=dict(\n        symbol=\"hexagon-dot\",\n        size=15\n    ),\n    yaxis='y2'\n)\n\ndata = [trace1, trace2, trace3]\nlayout = go.Layout(\n    barmode='group',\n    title = 'No such thing as bad press, right?',\n    width=900,\n    height=500,\n    margin=go.Margin(\n        l=75,\n        r=75,\n        b=120,\n        t=80,\n        pad=10\n    ),\n    paper_bgcolor='rgb(244, 238, 225)',\n    plot_bgcolor='rgb(244, 238, 225)',\n    yaxis = dict(\n        title= 'Number of likes/dislikes',\n        anchor = 'x',\n        rangemode='tozero'\n    ),   \n    yaxis2=dict(\n        title='Dislike percentage',\n        titlefont=dict(\n            color='rgb(148, 103, 189)'\n        ),\n        tickfont=dict(\n            color='rgb(148, 103, 189)'\n        ),\n        overlaying='y',\n        side='right',\n        anchor = 'x',\n        rangemode = 'tozero',\n        dtick = 0.165\n    ),\n    legend=dict(x=0.75, y=1)\n)\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.9. Tags wordcloud\n<a id=\"tags_wordcloud\"></a>\nThis section dedicated to tags that support the videos to reach the trending list."},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nfrom PIL import Image\nimport urllib\nimport requests\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nmask = np.array(Image.open(requests.get('http://www.clker.com/cliparts/O/i/x/Y/q/P/yellow-house-hi.png', stream=True).raw))\n\n# This function takes in your text and your mask and generates a wordcloud. \ndef generate_wordcloud(mask):\n    word_cloud = WordCloud(width = 512, height = 512, background_color='white', stopwords=STOPWORDS, mask=mask).generate(str(in_videos[\"tags\"]))\n    plt.figure(figsize=(10,8),facecolor = 'white', edgecolor='blue')\n    plt.imshow(word_cloud)\n    plt.axis('off')\n    plt.tight_layout(pad=0)\n    plt.show()\n    \n#Run the following to generate your wordcloud\ngenerate_wordcloud(mask)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a308395a3fc499b17367d0af06e628de37a63f36","_cell_guid":"8dad2506-94ae-4ea6-a6f5-44a1c128cfa6"},"cell_type":"markdown","source":"### 2.10. Likes vs Dislikes distribution!\n<a id=\"likes_vs_dislikes_distribution\"></a>"},{"metadata":{"_uuid":"2754b7aaaf794f5de65fa972848a4fe58a223065","_cell_guid":"8bb7d20c-27be-4f2e-ba0f-5883cd0d1168","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"in_videos_first['likes_log'] = np.log(in_videos['likes'] + 1)\nin_videos_first['dislikes_log'] = np.log(in_videos['dislikes'] + 1)\nhist_data = [in_videos_first[\"dislikes_log\"].values, in_videos_first[\"likes_log\"].values]\n\ngroup_labels = ['Dislikes log distribution', 'Likes log distribution']\ncolors = ['#A6ACEC', '#63F5EF']\n\n# Create distplot with curve_type set to 'normal'\nfig = ff.create_distplot(hist_data, group_labels, colors=colors,\n                         bin_size=0.5, show_rug=False)\n\n# Add title\nfig['layout'].update(title='Likes vs dislikes', legend=dict(x=0.65, y=0.8))\n\n# Plot!\npy.iplot(fig, filename='Hist and Curve')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Acknowledgments\n<a id=\"refer\"></a>"},{"metadata":{"_uuid":"ba51aa0fb74d878fe863640af7f8be9756594007","_cell_guid":"ac80859f-4d99-460c-b47f-316180a05dab"},"cell_type":"markdown","source":"Inspirations are drawn from various Kaggle projects but majorly incentive is from the following :\n\n1. https://www.kaggle.com/residentmario/creating-reading-and-writing\n2. https://www.kaggle.com/skalskip/youtube-data-exploration-and-plotly-visualization\n3. https://www.kaggle.com/kabure/extensive-usa-youtube-eda \n\nOur GitHub Project Link - https://github.com/RohitLearner/Youtube_India_Data_Exploration "}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}